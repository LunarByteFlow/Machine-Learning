{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LunarByteFlow/Machine-Learning/blob/master/Pytorch_workFlow_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHm1-iSYHgvN",
        "outputId": "ddcf2199-436f-4345-e0f2-72c694fab9bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 'data(prepare and load)',\n",
              " 2: 'build model',\n",
              " 3: 'fitting the model to data(training)',\n",
              " 4: 'Making predictions and evaluating a model(inference)',\n",
              " 5: 'saving and loading a model',\n",
              " 6: 'Putting it all together'}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "what_were_covering = {\n",
        "    1: \"data(prepare and load)\",\n",
        "    2:\"build model\",\n",
        "    3:\"fitting the model to data(training)\",\n",
        "    4:\"Making predictions and evaluating a model(inference)\",\n",
        "    5:\"saving and loading a model\",\n",
        "    6:\"Putting it all together\"\n",
        "}\n",
        "what_were_covering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RtDC4V1pUF_O",
        "outputId": "8dd0c363-8ec4-427e-efc9-8191ee1cfa99"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1+cu121'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of Pytorch's building blocks for Neural Networks.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zr3xMcQmJao"
      },
      "source": [
        "### 1. Data(Preparing and Loading)\n",
        "Data Can be almost anything in machine learning...\n",
        "* Excel spreadsheet\n",
        "* Images of any kind\n",
        "* Videos (Youtube has a lot of data...)\n",
        "* Audio like songs or podcast\n",
        "* DNA\n",
        "* Text\n",
        "Machine learning is a game of 2 parts\n",
        "1. Get Data into numerical representation\n",
        "2. Build a model to learn patterns in that numerical representation\n",
        "To showcase this let's create some **known** data using linear regression formula.\n",
        "We'll use a linear regression formula to make a straight line with known **Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6wNt8-6mWey",
        "outputId": "c71a8233-91ac-44b5-a410-e15158cc586b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "#Create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "X = torch.arange(start,end,step).unsqueeze(dim=1)\n",
        "y = bias + weight*X\n",
        "X[:10], y[:10]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHJECmk1wWUR",
        "outputId": "34473b0d-277c-4ffa-d767-4baa11f0574c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 50)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X), len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dnHP_o8yPYX"
      },
      "source": [
        "### Splitting data into training and test sets (one of the most important concepts in Machine Learning in general)\n",
        "let's create a training and test set with our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwXl3goh1GKW",
        "outputId": "4ded8424-32d9-4783-9934-b05cba9a6052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training X data: 40\n",
            "Training y data: 40\n",
            "Test X data: 10\n",
            "Test y data: 10\n"
          ]
        }
      ],
      "source": [
        "train_split = int(0.8 * len(X))\n",
        "X_train , y_train = X[:train_split],y[:train_split]\n",
        "X_test , y_test = X[train_split:],y[train_split:]\n",
        "print(f\"Training X data: {len(X_train)}\")\n",
        "print(f\"Training y data: {len(y_train)}\")\n",
        "print(f\"Test X data: {len(X_test)}\")\n",
        "print(f\"Test y data: {len(y_test)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8OXX4uPimRMh"
      },
      "outputs": [],
      "source": [
        "def plot_prediction(train_data = X_train, train_labels = y_train, test_data = X_test,test_labels = y_test,predictions = None ):\n",
        "  \"\"\"\n",
        "  Plots taining data, test data and compares predictions\n",
        "  \"\"\"\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\",s=4, label = \"Training Data\")\n",
        "  # plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\",s=4, label = \"Test Data\")\n",
        "  # Are there predictions\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions if they exist\n",
        "    plt.scatter(test_data, predictions, c=\"r\",s=4, label = \"Predictions data\")\n",
        "\n",
        "  plt.legend(prop={\"size\": 14})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2yFC5zHQpKiz",
        "outputId": "6dae5245-ddfa-473a-a61d-155dcaea6b7c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_prediction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlQoPl8wm6xd"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JqQLKnyKbFF"
      },
      "source": [
        "### Building out first Pytorch Model\n",
        "What our Model does\n",
        "* start with random values.\n",
        "* Look at training data and adjust the random values to better represent(or get closer to) the ideal values\n",
        "How does it do so?\n",
        "By two main algorithms.\n",
        "1. Gradient Decent. --> https://www.javatpoint.com/gradient-descent-in-machine-learning\n",
        "2. Back Propagation. -->https://www.geeksforgeeks.org/backpropagation-in-neural-network/\n",
        "What exactly does the forward method do?\n",
        "* It defines the computations performed at exery cell.\n",
        "* Should be overridden by all subclasses.\n",
        "* You need to define a forward method if you are going to sub class nn.module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VjYR05aAKhsc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "# Create linear regression model class\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1,requires_grad = True, dtype = torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,requires_grad = True, dtype = torch.float))\n",
        "\n",
        "  def forward(self,x:torch.Tensor)-> torch.Tensor:\n",
        "    return self.weights*x + self.bias # This is the linear regression formula\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TqFPkjL7jQq"
      },
      "source": [
        "### PyTorch Model building essentials\n",
        "* torch.nn -> contains all of the building blocks for computational graphs (neural networks are also called computational graphs)\n",
        "* torch.nn.parameter -> what parameters should our model try and learn often a pytorch layer from torch.nn will set these for us.\n",
        "* torch.nn.Module -> The base class for all neural network modules, if you subclass it, you have to overwrite() forward.\n",
        "* torch.optim -> this is where optimizers in pytorch live, they will help, they will help with gradient descent\n",
        "* def forward() -> all nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hu-4RNV5eMr",
        "outputId": "27fcb998-596a-451e-a51d-08c488e0f48f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model( this is a subclass of nn.Module)\n",
        "model_0 = LinearRegression()\n",
        "list(model_0.parameters())\n",
        "\n",
        "# list named parameters\n",
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyYsiM-Q-qyH"
      },
      "source": [
        "### Making Predictions using `torch.inference()` mode.\n",
        "To check our Model's Predictive power lets see how well it predicts `y_test` based on `x_text`\n",
        "When we pass data through our model, its going to run it through the `forward()`method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "K1DWwnzA9pOl",
        "outputId": "b5d2e1ff-b3f4-4969-afd6-4c6306bc5c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y for prediction values: tensor([[0.3982],\n",
            "        [0.4049],\n",
            "        [0.4116],\n",
            "        [0.4184],\n",
            "        [0.4251],\n",
            "        [0.4318],\n",
            "        [0.4386],\n",
            "        [0.4453],\n",
            "        [0.4520],\n",
            "        [0.4588]])\n",
            "Y data for testing: tensor([[0.8600],\n",
            "        [0.8740],\n",
            "        [0.8880],\n",
            "        [0.9020],\n",
            "        [0.9160],\n",
            "        [0.9300],\n",
            "        [0.9440],\n",
            "        [0.9580],\n",
            "        [0.9720],\n",
            "        [0.9860]])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "  y_pred = model_0(X_test)\n",
        "  print(f\"Y for prediction values: {y_pred}\")\n",
        "\n",
        "print(f\"Y data for testing: {y_test}\")\n",
        "# This is similar to torch.inference_mode but an older method\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(X_test)\n",
        "plot_prediction(predictions = y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh-3K0aKN9yu"
      },
      "source": [
        "### Training Mode\n",
        "The whole idea of training is for a model to move from *Unknown* Parameters (these may be random) to some *Known* parameters.\n",
        "Or in other words from a poor representation of the data to a better representation of the data.\n",
        "One way to measure how poor or how wrong your model's predictions are is to use  a loss function.\n",
        "Link for refrence -> https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "* Note : Loss Function may also be called cost function or criterion in different areas.For our case we are going to refer it as a loss function.\n",
        "Things we need to train:\n",
        "\n",
        "* **Loss Function**: A loss functions is used to measure how wrong your model's predictions are to the ideal output, The lower the better.\n",
        "* Optimizer: takes into account the loss of the model and adjust the model's parameters (e.g: Weight and bias) to improve the loss function.\n",
        "* **Hyperparameters**: Hyoerparameters is a value that us as a data scientist or Machine learning Engineer set.\n",
        "\n",
        "And specifically for PyTorch, we need:\n",
        "* A training loop\n",
        "* A testing Loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0AUxhtpAbsSG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# setup a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "#setup an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.01) #lr = learning rate (hyperparameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "il_J_Lj8X8Co",
        "outputId": "1df4eb86-e54a-4b2c-cff9-416d8859cef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.01\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_fn\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCB1rIGAcssr"
      },
      "source": [
        "### Building a training loop and a testing loop in pytorch.\n",
        "A couple of things we need in a training loop:\n",
        "0. Loop through the data.\n",
        "1. This involves moving data through our model's `forward()` functions - also called forward propagation.\n",
        "2. calculate the loss, ( compare forward pass predictions to ground truth lables)\n",
        "3. Optimizer zero grad.\n",
        "4. Loss backward - Moves backwards to the network to calculate the gradients of each of the parameters of our model with respect to the loss - **backpropagation**\n",
        "5. Optimizer Step - Use the optimizer to adjust our model's parameters to try and minimize(improve) the loss. **Optimizer Step**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nvGTEhviYQz",
        "outputId": "f69dc746-8763-4a17-ab28-1cc94501f0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0| loss: 0.31288138031959534|Test Loss 0.48106518387794495\n",
            "OrderedDict([('weights', tensor([0.3406])), ('bias', tensor([0.1388]))])\n",
            "Epoch: 10| loss: 0.1976713240146637|Test Loss 0.3463551998138428\n",
            "OrderedDict([('weights', tensor([0.3796])), ('bias', tensor([0.2388]))])\n",
            "Epoch: 20| loss: 0.08908725529909134|Test Loss 0.21729660034179688\n",
            "OrderedDict([('weights', tensor([0.4184])), ('bias', tensor([0.3333]))])\n",
            "Epoch: 30| loss: 0.053148526698350906|Test Loss 0.14464017748832703\n",
            "OrderedDict([('weights', tensor([0.4512])), ('bias', tensor([0.3768]))])\n",
            "Epoch: 40| loss: 0.04543796554207802|Test Loss 0.11360953003168106\n",
            "OrderedDict([('weights', tensor([0.4748])), ('bias', tensor([0.3868]))])\n",
            "Epoch: 50| loss: 0.04167863354086876|Test Loss 0.09919948130846024\n",
            "OrderedDict([('weights', tensor([0.4938])), ('bias', tensor([0.3843]))])\n",
            "Epoch: 60| loss: 0.03818932920694351|Test Loss 0.08886633068323135\n",
            "OrderedDict([('weights', tensor([0.5116])), ('bias', tensor([0.3788]))])\n",
            "Epoch: 70| loss: 0.03476089984178543|Test Loss 0.0805937647819519\n",
            "OrderedDict([('weights', tensor([0.5288])), ('bias', tensor([0.3718]))])\n",
            "Epoch: 80| loss: 0.03132382780313492|Test Loss 0.07232122868299484\n",
            "OrderedDict([('weights', tensor([0.5459])), ('bias', tensor([0.3648]))])\n",
            "Epoch: 90| loss: 0.02788739837706089|Test Loss 0.06473556160926819\n",
            "OrderedDict([('weights', tensor([0.5629])), ('bias', tensor([0.3573]))])\n",
            "Epoch: 100| loss: 0.024458957836031914|Test Loss 0.05646304413676262\n",
            "OrderedDict([('weights', tensor([0.5800])), ('bias', tensor([0.3503]))])\n",
            "Epoch: 110| loss: 0.021020207554101944|Test Loss 0.04819049686193466\n",
            "OrderedDict([('weights', tensor([0.5972])), ('bias', tensor([0.3433]))])\n",
            "Epoch: 120| loss: 0.01758546568453312|Test Loss 0.04060482233762741\n",
            "OrderedDict([('weights', tensor([0.6141])), ('bias', tensor([0.3358]))])\n",
            "Epoch: 130| loss: 0.014155393466353416|Test Loss 0.03233227878808975\n",
            "OrderedDict([('weights', tensor([0.6313])), ('bias', tensor([0.3288]))])\n",
            "Epoch: 140| loss: 0.010716589167714119|Test Loss 0.024059748277068138\n",
            "OrderedDict([('weights', tensor([0.6485])), ('bias', tensor([0.3218]))])\n",
            "Epoch: 150| loss: 0.0072835334576666355|Test Loss 0.016474086791276932\n",
            "OrderedDict([('weights', tensor([0.6654])), ('bias', tensor([0.3143]))])\n",
            "Epoch: 160| loss: 0.0038517764769494534|Test Loss 0.008201557211577892\n",
            "OrderedDict([('weights', tensor([0.6826])), ('bias', tensor([0.3073]))])\n",
            "Epoch: 170| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 180| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 190| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 200| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 210| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 220| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 230| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 240| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 250| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 260| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 270| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 280| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 290| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 300| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 310| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 320| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 330| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 340| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 350| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 360| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 370| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 380| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 390| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 400| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 410| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 420| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 430| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 440| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 450| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 460| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 470| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 480| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 490| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 500| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 510| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 520| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 530| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 540| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 550| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 560| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 570| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 580| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 590| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 600| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 610| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 620| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 630| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 640| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 650| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 660| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 670| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 680| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 690| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 700| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 710| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 720| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 730| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 740| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 750| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 760| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 770| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 780| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 790| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 800| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 810| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 820| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 830| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 840| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 850| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 860| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 870| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 880| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 890| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 900| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 910| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 920| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 930| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 940| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 950| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 960| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 970| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 980| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 990| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1000| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1010| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1020| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1030| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1040| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1050| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1060| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1070| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1080| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1090| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1100| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1110| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1120| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1130| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1140| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1150| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1160| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1170| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1180| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1190| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1200| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1210| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1220| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1230| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1240| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1250| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1260| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1270| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1280| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1290| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1300| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1310| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1320| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1330| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1340| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1350| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1360| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1370| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1380| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1390| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1400| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1410| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1420| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1430| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1440| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1450| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1460| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1470| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1480| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1490| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1500| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1510| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1520| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1530| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1540| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1550| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1560| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1570| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1580| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1590| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1600| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1610| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1620| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1630| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1640| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1650| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1660| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1670| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1680| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1690| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1700| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1710| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1720| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1730| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1740| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1750| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1760| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1770| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1780| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1790| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1800| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1810| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1820| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1830| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1840| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1850| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1860| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1870| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1880| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1890| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1900| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1910| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1920| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1930| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1940| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1950| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1960| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1970| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1980| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 1990| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2000| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2010| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2020| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2030| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2040| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2050| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2060| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2070| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2080| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2090| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2100| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2110| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2120| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2130| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2140| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2150| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2160| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2170| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2180| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2190| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2200| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2210| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2220| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2230| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2240| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2250| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2260| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2270| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2280| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2290| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2300| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2310| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2320| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2330| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2340| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2350| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2360| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2370| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2380| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2390| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2400| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2410| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2420| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2430| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2440| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2450| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2460| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2470| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2480| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2490| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2500| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2510| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2520| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2530| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2540| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2550| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2560| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2570| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2580| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2590| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2600| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2610| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2620| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2630| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2640| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2650| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2660| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2670| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2680| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2690| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2700| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2710| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2720| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2730| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2740| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2750| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2760| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2770| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2780| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2790| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2800| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2810| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2820| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2830| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2840| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2850| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2860| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2870| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2880| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2890| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2900| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2910| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2920| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2930| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2940| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2950| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2960| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2970| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2980| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Epoch: 2990| loss: 0.008932482451200485|Test Loss 0.005023092031478882\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n"
          ]
        }
      ],
      "source": [
        "# An epocs is one loop through the data... this is a hyperparameter because we have set it ourselves.\n",
        "epochs = 3000\n",
        "# tracking experiments\n",
        "epoc_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "# 0 loop through the data\n",
        "for epoc in range(epochs):\n",
        "  # set the model to training mode.\n",
        "  model_0.train() # train mode in pytorch set all parameters that require parameters to require parameters.\n",
        "\n",
        "  # 1. Forward Pass\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  # 2. Calculate the loss.\n",
        "  loss = loss_fn(y_pred,y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. perform backpropagation with respect to the parameters of the model.\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (gradient descent)\n",
        "  optimizer.step() # by default how the optiizer changes will accumulate through the loop so... we have to zero it above in step 3\n",
        "\n",
        "  model_0.eval() # turns of different settings not needed for evaluation (drop out/ batch norm layers)\n",
        "  with torch.inference_mode(): # This turns off gradient tracking.\n",
        "    test_pred = model_0(X_test)\n",
        "    test_loss = loss_fn(test_pred,y_test)\n",
        "\n",
        "  if epoc % 10 == 0 :\n",
        "    epoc_count.append(epoc)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch: {epoc}| loss: {loss}|Test Loss {test_loss}\")\n",
        "    print(model_0.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "  # print(f\"loss = {loss}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uz_v7fSr7f4q"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred_train = model_0(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "PdZilKibFe1M",
        "outputId": "c0c7cde2-6133-405a-ed37-f3bbd4bf4d78"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-39e30392cb7f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-b53d81ac9d27>\u001b[0m in \u001b[0;36mplot_prediction\u001b[0;34m(train_data, train_labels, test_data, test_labels, predictions)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Plot the predictions if they exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Predictions data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 2862\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   2863\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4580\u001b[0m         \u001b[0;31m# unless its argument is a masked array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4584\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, a, *args, **params)\u001b[0m\n\u001b[1;32m   6873\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6875\u001b[0;31m         \u001b[0mmarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6876\u001b[0m         \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m   8297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmasked_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order)\u001b[0m\n\u001b[1;32m   2818\u001b[0m         \"\"\"\n\u001b[1;32m   2819\u001b[0m         \u001b[0;31m# Process data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2820\u001b[0;31m         _data = np.array(data, dtype=dtype, copy=copy,\n\u001b[0m\u001b[1;32m   2821\u001b[0m                          order=order, subok=True, ndmin=ndmin)\n\u001b[1;32m   2822\u001b[0m         \u001b[0m_baseclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_baseclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_prediction(predictions = y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EJY0M6ooEv99"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O3uoFTCZBC62"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "predictions = y_preds.detach().numpy()\n",
        "plot_prediction(predictions =predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CxsbfFrJfYSI"
      },
      "outputs": [],
      "source": [
        "print(f\"The ideal predictions for our model: {weight,bias}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YB6gOUcmkymx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# plot the loss curves of our Linear Regression Model.\n",
        "plt.plot(epoc_count, np.array(torch.tensor(loss_values).numpy()))\n",
        "plt.plot(epoc_count, test_loss_values,label = test_loss)\n",
        "plt.title(\"Training and Test loss curves\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss vs Epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYKl4p_MWCvn"
      },
      "source": [
        "### Saving a Model in PyTorch\n",
        "There are three main methods you should know about for saving and loading models in pytorch:\n",
        "1. `torch.save()` - Allows you to save a Pytorch object in python's pickle format.\n",
        "2. `torch.load()` - Allows you to load a saved PyTorch object.\n",
        "3. `torch.nn.Module.load_state_dict()` -this allows to load a Model's saved state dictionary.\n",
        "get more informations on : https://pytorch.org/tutorials/beginner/saving_loading_models.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ULHpt47LWHMP"
      },
      "outputs": [],
      "source": [
        "# Saving our PyTorch Model.\n",
        "from pathlib import Path\n",
        "# 1. Create Model Directory.\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "#2. Create Model save path\n",
        "MODEL_NAME = \"Linear_regression_model.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "MODEL_SAVE_PATH\n",
        "\n",
        "# 3. Save the model state dict\n",
        "print(f\"Saving the model {model_0}, to the loacation ; {MODEL_SAVE_PATH}\")\n",
        "torch.save( obj = model_0.state_dict(),f = MODEL_SAVE_PATH )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoNbbPUMUPt-"
      },
      "source": [
        "## loading a PyTorch Model\n",
        "Since we saved our model's `state_dict()` rather than the entire model, we'll create a new instance of our Model class and load the  saved `state_dict()` into that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I7dJzTuuVJ_6"
      },
      "outputs": [],
      "source": [
        "# To load in a saved state_dict we have to instantiate a new instance of our model class.\n",
        "loaded_model_0 = LinearRegression()\n",
        "# Load the saved state dict of model_0 (this will update the new instance with updated parameters)\n",
        "loaded_model_0.load_state_dict(torch.load(f = MODEL_SAVE_PATH))\n",
        "loaded_model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s_2id5oJXW4P"
      },
      "outputs": [],
      "source": [
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds == loaded_model_0(X_test)\n",
        "print(loaded_model_preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LwTngQ-0X8jQ"
      },
      "outputs": [],
      "source": [
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds == model_0(X_test)\n",
        "print(y_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqDIoVpnBXUn"
      },
      "source": [
        "### Putting it all together\n",
        "Let's go back through all the previous steps and see it all in one place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cEolyuoHBoZI"
      },
      "outputs": [],
      "source": [
        "# import Pytorch and Matplotlib\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        " # check version of pytorch\n",
        "torch.__version__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAi8kQKsDHg3"
      },
      "source": [
        "### Create device Agnostic code\n",
        "This means that if we have access to a GPU our Model will use it (for Potentially faster computing). If no GPU is available our code will default to CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZU9emaFtE-pO"
      },
      "outputs": [],
      "source": [
        "# setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using Devise: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jPYErRb6GGrx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "weight = 0.10\n",
        "bias = 0.7\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start,end,step).unsqueeze(dim=1)\n",
        "y = bias + weight*X\n",
        "X[:10], y[:30]\n",
        "len(X),len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0QoCK2poHBN7"
      },
      "outputs": [],
      "source": [
        "train_split = int(0.8*len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WbSbhFVdH_uD"
      },
      "outputs": [],
      "source": [
        "def plot_Linear_regression(train_data = X_train, train_labels = y_train, test_data = X_test, test_labels =y_test, predictions = None):\n",
        "  \"\"\"\n",
        "  Plots taining data, test data and compares predictions\n",
        "  \"\"\"\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\",s=4, label = \"Training Data\")\n",
        "  # plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\",s=4, label = \"Test Data\")\n",
        "  # Are there predictions\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions if they exist\n",
        "    plt.scatter(test_data, predictions, c=\"r\",s=4, label = \"Predictions data\")\n",
        "\n",
        "  plt.legend(prop={\"size\": 14})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y-VETaFyMMNY"
      },
      "outputs": [],
      "source": [
        "plot_Linear_regression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pWA3_fRMMmJY"
      },
      "outputs": [],
      "source": [
        "plot_Linear_regression(predictions = X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7lNi84JxNT0X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, requires_grad = True,dtype = torch.float ))\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad = True,dtype = torch.float ))\n",
        "  def forward(self, x:torch.Tensor) ->torch.Tensor:\n",
        "    return self.weights*x + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EzPhNojpOdQQ"
      },
      "outputs": [],
      "source": [
        "# create a random seed\n",
        "LR_model = LinearRegression()\n",
        "LR_model.state_dict()\n",
        "\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(params = LR_model.parameters(), lr = 0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oKvZu5jlQKEf"
      },
      "outputs": [],
      "source": [
        "epochs = 300\n",
        "epoc_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "# 0 Loop  through the data\n",
        "for epoc in range(epochs):\n",
        "  #Set the model to training mode\n",
        "  LR_model.train()\n",
        "\n",
        "  # 1 Forward Pass\n",
        "  y_estimated = LR_model( X_train)\n",
        "\n",
        "  # 2 Calculate the loss\n",
        "  loss = loss_fn(y_estimated,y_train)\n",
        "\n",
        "  # 3 Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4 perform back propagation\n",
        "  loss.backward()\n",
        "\n",
        "  # 5 step the optimizer\n",
        "  optimizer.step()\n",
        "\n",
        "  #set the model to testing mode\n",
        "  LR_model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    test_pred = LR_model(X_test)\n",
        "    test_loss = loss_fn(test_pred,y_test)\n",
        "\n",
        "  if epoc % 10 == 0 :\n",
        "    epoc_count.append(epoc)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    # print(f\"Epoch: {epoc}| loss: {loss}|Test Loss {test_loss}\")\n",
        "    # print(LR_model.state_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8xfLhELLSZlP"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = LR_model(X_test)\n",
        "import numpy\n",
        "predictions =   y_preds.detach().numpy()\n",
        "plot_Linear_regression(predictions =predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZHQ9uFfyipAt"
      },
      "outputs": [],
      "source": [
        "# Create a linear regression model with nn.Linear\n",
        "import torch\n",
        "from torch import nn\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # using nn.Linear to create the model parameters\n",
        "    self.linear_layer = nn.Linear(in_features = 1, out_features = 1)\n",
        "  def forward(self,x:torch.Tensor)-> torch.Tensor:\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "\n",
        "\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixvB7OX7pW5J"
      },
      "source": [
        "# Loading a Saved Model in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qtfe4B44pbNX"
      },
      "outputs": [],
      "source": [
        "# Loading a saved model in pytorch\n",
        "# Create a new instance of the linear regression model V2\n",
        "loaded_model_1 = LinearRegressionModelV2()\n",
        "# Load the saved state_dict\n",
        "loaded_model_1.load_state_dict(torch.load(f= MODEL_SAVE_PATH))\n",
        "\n",
        "# put the loaded model to device\n",
        "loaded_model_1.to(device)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODLsYCr+gpToo+PSroptMC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}